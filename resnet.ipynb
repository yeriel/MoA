{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVi1SsjyptVU"
      },
      "outputs": [],
      "source": [
        "#######################\n",
        "###  Global paths   ###\n",
        "#######################\n",
        "custom_module_path = f'/content/drive/MyDrive/MoA/utilites'\n",
        "dataset_path = f'/content/drive/MyDrive/MoA/dataset'\n",
        "\n",
        "#######################\n",
        "### Library imports ###\n",
        "#######################\n",
        "# standard library\n",
        "import os\n",
        "import sys\n",
        "import copy\n",
        "\n",
        "#custom tooling\n",
        "sys.path.append(custom_module_path)\n",
        "import resnet\n",
        "import preprocess"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Configurations\n",
        "\n",
        "length = 877  # Length of each Segment\n",
        "model_name = 'ResNet18_2_output'  # DenseNet Models\n",
        "model_width = 64  # Width of the Initial Layer, subsequent layers start from here\n",
        "num_channel = 1  # Number of Input Channels in the Model\n",
        "problem_type = 'Classification'  # Classification or Regression\n",
        "output_nums = 206  # Number of Class for Classification Problems, always '1' for Regression Problems\n",
        "  \n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-3, decay=1e-5)\n",
        "  \n",
        "Model = resnet.ResNet(length, num_channel, model_width, problem_type=problem_type, output_nums=output_nums, pooling='avg',dropout_rate=0.3).ResNet_18_LSTM()\n",
        "Model.compile(opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "Model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3GOf_LOr-iE",
        "outputId": "c4a93c1b-1d4d-4aeb-d9d9-7e4c7ca2a2f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 877, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)             (None, 439, 64)      512         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 439, 64)     256         ['conv1d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 439, 64)      0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 219, 64)     0           ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)             (None, 219, 64)      12352       ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 219, 64)     256         ['conv1d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 219, 64)      0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)             (None, 219, 64)      12352       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 219, 64)     256         ['conv1d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 219, 64)      0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 219, 64)      0           ['activation_24[0][0]',          \n",
            "                                                                  'max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 219, 64)      0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)             (None, 219, 64)      12352       ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 219, 64)     256         ['conv1d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 219, 64)      0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_21 (Conv1D)             (None, 219, 64)      12352       ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 219, 64)     256         ['conv1d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 219, 64)      0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 219, 64)      0           ['activation_27[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 219, 64)      0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_22 (Conv1D)             (None, 110, 128)     24704       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 110, 128)    512         ['conv1d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 110, 128)     0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_23 (Conv1D)             (None, 110, 128)     49280       ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 110, 128)    512         ['conv1d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 110, 128)     0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_24 (Conv1D)             (None, 110, 128)     49280       ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 110, 128)    512         ['conv1d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 110, 128)     0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_25 (Conv1D)             (None, 110, 128)     49280       ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 110, 128)    512         ['conv1d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 110, 128)     0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 110, 128)     0           ['activation_32[0][0]',          \n",
            "                                                                  'activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 110, 128)     0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_26 (Conv1D)             (None, 55, 256)      98560       ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 55, 256)     1024        ['conv1d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 55, 256)      0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_27 (Conv1D)             (None, 55, 256)      196864      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 55, 256)     1024        ['conv1d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 55, 256)      0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_28 (Conv1D)             (None, 55, 256)      196864      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 55, 256)     1024        ['conv1d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 55, 256)      0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_29 (Conv1D)             (None, 55, 256)      196864      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 55, 256)     1024        ['conv1d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 55, 256)      0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 55, 256)      0           ['activation_37[0][0]',          \n",
            "                                                                  'activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 55, 256)      0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_30 (Conv1D)             (None, 28, 512)      393728      ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 28, 512)     2048        ['conv1d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 28, 512)      0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_31 (Conv1D)             (None, 28, 512)      786944      ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 28, 512)     2048        ['conv1d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 28, 512)      0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_32 (Conv1D)             (None, 28, 512)      786944      ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 28, 512)     2048        ['conv1d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 28, 512)      0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_33 (Conv1D)             (None, 28, 512)      786944      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 28, 512)     2048        ['conv1d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 28, 512)      0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 28, 512)      0           ['activation_42[0][0]',          \n",
            "                                                                  'activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 877, 1)       12          ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 28, 512)      0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 877, 512)     1024        ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling1d_2 (Gl  (None, 512)         0           ['activation_43[0][0]']          \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " global_average_pooling1d_3 (Gl  (None, 512)         0           ['dense_4[0][0]']                \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 512)          0           ['global_average_pooling1d_2[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'global_average_pooling1d_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 128)          65664       ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 64)           8256        ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 206)          13390       ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,770,138\n",
            "Trainable params: 3,762,330\n",
            "Non-trainable params: 7,808\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_data(X,y, size_test=0.1):\n",
        "    X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=size_test, random_state=19)\n",
        "    return X_tr,X_test,y_tr,y_test \n",
        "\n",
        "def preprocess_data(X,y):\n",
        "    transformer = preprocess.Preprocessor() \n",
        "    transformer.fit(X)\n",
        "    X = transformer.transform(X)\n",
        "    y = y.drop([\"sig_id\"], axis = 1).values.astype(\"float32\") \n",
        "    return pd.DataFrame(X),pd.DataFrame(y)\n",
        "\n",
        "drugs = pd.read_csv(f'{dataset_path}/train_drug.csv')\n",
        "train_drug = pd.read_csv(f'{dataset_path}/train_drug.csv')\n",
        "X = pd.read_csv(f'{dataset_path}/train_features.csv')\n",
        "y = pd.read_csv(f'{dataset_path}/train_targets_scored.csv')\n",
        "\n",
        "X,y = preprocess_data(X,y)\n",
        "X_train, X_test, y_train, y_test = split_data(X,y)\n",
        "X_train, X_val, y_train, y_val = split_data(X_train,y_train,0.2)"
      ],
      "metadata": {
        "id": "m_KZ8Ov_u6MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'x_train: {X_train.shape}\\nx_val: {X_val.shape}')\n",
        "print(f'y_train: {y_train.shape}\\ny_val: {y_val.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUwE31sb0VRG",
        "outputId": "fdd8c804-1efe-4b81-e264-e99915087e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train: (17145, 877)\n",
            "x_val: (4287, 877)\n",
            "y_train: (17145, 206)\n",
            "y_val: (4287, 206)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val = np.array(X_train), np.array(X_val)\n",
        "y_train, y_val = y_train.values.astype(\"float32\"), y_val.values.astype(\"float32\")"
      ],
      "metadata": {
        "id": "qIUMFxTvveXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = Model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=30, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V4wPxt2wxNk",
        "outputId": "6b5a3875-3c70-4e55-f87f-9018b6282464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "536/536 [==============================] - 40s 52ms/step - loss: 0.0675 - accuracy: 0.0053 - val_loss: 0.0525 - val_accuracy: 9.3305e-04\n",
            "Epoch 2/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0028 - val_loss: 0.0525 - val_accuracy: 6.9979e-04\n",
            "Epoch 3/30\n",
            "536/536 [==============================] - 28s 51ms/step - loss: 0.0528 - accuracy: 0.0036 - val_loss: 0.0525 - val_accuracy: 9.3305e-04\n",
            "Epoch 4/30\n",
            "536/536 [==============================] - 28s 53ms/step - loss: 0.0528 - accuracy: 0.0038 - val_loss: 0.0525 - val_accuracy: 0.0023\n",
            "Epoch 5/30\n",
            "536/536 [==============================] - 32s 60ms/step - loss: 0.0528 - accuracy: 0.0045 - val_loss: 0.0525 - val_accuracy: 0.0044\n",
            "Epoch 6/30\n",
            "536/536 [==============================] - 29s 54ms/step - loss: 0.0528 - accuracy: 0.0032 - val_loss: 0.0525 - val_accuracy: 0.0056\n",
            "Epoch 7/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0045 - val_loss: 0.0525 - val_accuracy: 0.0103\n",
            "Epoch 8/30\n",
            "536/536 [==============================] - 27s 51ms/step - loss: 0.0528 - accuracy: 0.0049 - val_loss: 0.0525 - val_accuracy: 0.0058\n",
            "Epoch 9/30\n",
            "536/536 [==============================] - 28s 52ms/step - loss: 0.0528 - accuracy: 0.0034 - val_loss: 0.0525 - val_accuracy: 0.0042\n",
            "Epoch 10/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0029 - val_loss: 0.0525 - val_accuracy: 0.0049\n",
            "Epoch 11/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0026 - val_loss: 0.0525 - val_accuracy: 0.0047\n",
            "Epoch 12/30\n",
            "536/536 [==============================] - 32s 60ms/step - loss: 0.0528 - accuracy: 0.0026 - val_loss: 0.0525 - val_accuracy: 0.0030\n",
            "Epoch 13/30\n",
            "536/536 [==============================] - 31s 57ms/step - loss: 0.0528 - accuracy: 0.0025 - val_loss: 0.0525 - val_accuracy: 0.0035\n",
            "Epoch 14/30\n",
            "536/536 [==============================] - 28s 53ms/step - loss: 0.0528 - accuracy: 0.0024 - val_loss: 0.0525 - val_accuracy: 0.0037\n",
            "Epoch 15/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0023 - val_loss: 0.0525 - val_accuracy: 0.0033\n",
            "Epoch 16/30\n",
            "536/536 [==============================] - 28s 52ms/step - loss: 0.0528 - accuracy: 0.0020 - val_loss: 0.0525 - val_accuracy: 0.0035\n",
            "Epoch 17/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0022 - val_loss: 0.0525 - val_accuracy: 0.0037\n",
            "Epoch 18/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0021 - val_loss: 0.0525 - val_accuracy: 0.0033\n",
            "Epoch 19/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0023 - val_loss: 0.0525 - val_accuracy: 0.0033\n",
            "Epoch 20/30\n",
            "536/536 [==============================] - 28s 52ms/step - loss: 0.0528 - accuracy: 0.0026 - val_loss: 0.0525 - val_accuracy: 0.0033\n",
            "Epoch 21/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0025 - val_loss: 0.0525 - val_accuracy: 0.0035\n",
            "Epoch 22/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0024 - val_loss: 0.0525 - val_accuracy: 0.0037\n",
            "Epoch 23/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0027 - val_loss: 0.0525 - val_accuracy: 0.0033\n",
            "Epoch 24/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0022 - val_loss: 0.0525 - val_accuracy: 0.0033\n",
            "Epoch 25/30\n",
            "536/536 [==============================] - 28s 51ms/step - loss: 0.0528 - accuracy: 0.0024 - val_loss: 0.0525 - val_accuracy: 0.0033\n",
            "Epoch 26/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0026 - val_loss: 0.0525 - val_accuracy: 0.0037\n",
            "Epoch 27/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0023 - val_loss: 0.0525 - val_accuracy: 0.0033\n",
            "Epoch 28/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0026 - val_loss: 0.0525 - val_accuracy: 0.0035\n",
            "Epoch 29/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0020 - val_loss: 0.0525 - val_accuracy: 0.0030\n",
            "Epoch 30/30\n",
            "536/536 [==============================] - 27s 50ms/step - loss: 0.0528 - accuracy: 0.0026 - val_loss: 0.0525 - val_accuracy: 0.0037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plotErrors(train_error, val_error, name='by Resnet'):  \n",
        "    plt.plot(train_error, color='red', marker='o', label='Train Loss')\n",
        "    plt.plot(val_error, color='blue', marker='o', label='Val Loss')\n",
        "    plt.title(f' train v/s validation error {name}')\n",
        "    plt.xlabel('# epochs')\n",
        "    plt.ylabel('Error loss') \n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.show()\n",
        "\n",
        "plotErrors(history.history['loss'],history.history['val_loss'])"
      ],
      "metadata": {
        "id": "WM3Y6Dq05PGm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "224d200b-6896-454e-a692-5eef04accdcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}